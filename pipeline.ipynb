{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82d9048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from utils.dataset import VCTKDataset\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from src.model.cvae_tacotron_wrapper import CVAETacotron2, cvae_taco_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8434970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected speakers: ['p323', 'p301', 'p240', 'p299', 'p225', 'p285', 'p252', 'p279', 'p287', 'p311']\n",
      "Speaker 0: p323: F, 19yo, SouthAfrican (Pretoria)\n",
      "Speaker 1: p301: F, 23yo, American (North Carolina)\n",
      "Speaker 2: p240: F, 21yo, English (Southern England)\n",
      "Speaker 3: p299: F, 25yo, American (California)\n",
      "Speaker 4: p225: F, 23yo, English (Southern England)\n",
      "Speaker 5: p285: M, 21yo, Scottish (Edinburgh)\n",
      "Speaker 6: p252: M, 22yo, Scottish (Edinburgh)\n",
      "Speaker 7: p279: M, 23yo, English (Leicester)\n",
      "Speaker 8: p287: M, 23yo, English (York)\n",
      "Speaker 9: p311: M, 21yo, American (Iowa)\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "dataset = VCTKDataset(\"./dataset/VCTK\",)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4,\n",
    "                    collate_fn=VCTKDataset.collate_cvae)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52197cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: torch.Size([32, 76]), text_len: torch.Size([32]), mel: torch.Size([32, 80, 562]), mel_len: torch.Size([32]), gate: torch.Size([32, 562]), spk: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for batch in loader:\n",
    "    text, text_len, mel, mel_len, gate, spk = batch\n",
    "    print(f\"text: {text.shape}, text_len: {text_len.shape}, mel: {mel.shape}, mel_len: {mel_len.shape}, gate: {gate.shape}, spk: {spk.shape}\")\n",
    "    break  # Remove this line to iterate through the entire dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc9987e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\jx/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\n",
      "C:\\Users\\jx/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\\PyTorch\\Classification\\ConvNets\\image_classification\\models\\common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "C:\\Users\\jx/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\\PyTorch\\Classification\\ConvNets\\image_classification\\models\\efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "e:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\src\\model\\cvae_tacotron_wrapper.py:63: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  speaker_look_up = torch.tensor([i for i in speaker_emb_dict.values()])\n"
     ]
    }
   ],
   "source": [
    "model = CVAETacotron2(ckpt_path=\"./src/model/tacotron2_pretrained.pt\", z_dim=64, spk_dim_raw=256, spk_dim_proj=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c649a531",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m optimizer = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text, text_len, mel, mel_len, gate, spk_id \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[32m      3\u001b[39m     text, text_len   = text.to(device), text_len.cuda()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:100\u001b[39m, in \u001b[36mAdam.__init__\u001b[39m\u001b[34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused, decoupled_weight_decay)\u001b[39m\n\u001b[32m     85\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTensor betas[1] must be 1-element\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     87\u001b[39m defaults = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m     88\u001b[39m     lr=lr,\n\u001b[32m     89\u001b[39m     betas=betas,\n\u001b[32m   (...)\u001b[39m\u001b[32m     98\u001b[39m     decoupled_weight_decay=decoupled_weight_decay,\n\u001b[32m     99\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:369\u001b[39m, in \u001b[36mOptimizer.__init__\u001b[39m\u001b[34m(self, params, defaults)\u001b[39m\n\u001b[32m    366\u001b[39m     param_groups = [{\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m: param_groups}]\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;28mself\u001b[39m._warned_capturable_if_run_uncaptured = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\_compile.py:46\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m disable_fn = \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[33m\"\u001b[39m\u001b[33m__dynamo_disable\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m disable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\n\u001b[32m     48\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive)\n\u001b[32m     49\u001b[39m     fn.__dynamo_disable = disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\_dynamo\\__init__.py:13\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mTorchDynamo is a Python-level JIT compiler designed to make unmodified PyTorch programs faster.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mTorchDynamo hooks into the frame evaluation API in CPython (PEP 523) to dynamically modify Python\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \u001b[33;03mseamlessly optimize PyTorch programs, including those using modern Python features.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config, convert_frame, eval_frame, resume_execution\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:52\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mguards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GlobalStateGuard\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_convert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorifyState\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_logging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structured\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:57\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexperimental\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_shapes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m guard_bool\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_functools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cache_method\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     58\u001b[39m     config,\n\u001b[32m     59\u001b[39m     exc,\n\u001b[32m     60\u001b[39m     graph_break_hints,\n\u001b[32m     61\u001b[39m     logging \u001b[38;5;28;01mas\u001b[39;00m torchdynamo_logging,\n\u001b[32m     62\u001b[39m     trace_rules,\n\u001b[32m     63\u001b[39m     variables,\n\u001b[32m     64\u001b[39m )\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbytecode_analysis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     66\u001b[39m     get_indexof,\n\u001b[32m     67\u001b[39m     JUMP_OPNAMES,\n\u001b[32m     68\u001b[39m     livevars_analysis,\n\u001b[32m     69\u001b[39m     propagate_line_nums,\n\u001b[32m     70\u001b[39m )\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbytecode_transformation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     72\u001b[39m     cleaned_instructions,\n\u001b[32m     73\u001b[39m     create_call_function,\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     unique_id,\n\u001b[32m     81\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py:32\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresume_execution\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TORCH_DYNAMO_RESUME_IN_PREFIX\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m getfile, hashable, NP_SUPPORTED_MODULES, unwrap_if_wrapper\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvariables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     33\u001b[39m     BuiltinVariable,\n\u001b[32m     34\u001b[39m     FunctionalCallVariable,\n\u001b[32m     35\u001b[39m     FunctorchHigherOrderVariable,\n\u001b[32m     36\u001b[39m     LocalGeneratorFunctionVariable,\n\u001b[32m     37\u001b[39m     LocalGeneratorObjectVariable,\n\u001b[32m     38\u001b[39m     NestedUserFunctionVariable,\n\u001b[32m     39\u001b[39m     PolyfilledFunctionVariable,\n\u001b[32m     40\u001b[39m     SkipFunctionVariable,\n\u001b[32m     41\u001b[39m     TorchInGraphFunctionVariable,\n\u001b[32m     42\u001b[39m     UserFunctionVariable,\n\u001b[32m     43\u001b[39m     UserMethodVariable,\n\u001b[32m     44\u001b[39m )\n\u001b[32m     47\u001b[39m np: Optional[types.ModuleType] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\__init__.py:19\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThis package implements variable tracking and symbolic execution capabilities for Dynamo,\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mwhich are essential for converting Python code into FX graphs. It provides a comprehensive\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m \u001b[33;03mallows Dynamo to accurately trace and optimize Python code while preserving its semantics.\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VariableTracker\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbuiltin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BuiltinVariable\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstant\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConstantVariable, EnumVariable\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\base.py:581\u001b[39m\n\u001b[32m    577\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    578\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(typestr, objs))\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\builder.py:86\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mguards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GuardBuilder, install_guard, make_dupe_guard\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpgo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     80\u001b[39m     auto_dynamic,\n\u001b[32m     81\u001b[39m     auto_unset,\n\u001b[32m   (...)\u001b[39m\u001b[32m     84\u001b[39m     process_automatic_dynamic,\n\u001b[32m     85\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mside_effects\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SideEffects\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msource\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     88\u001b[39m     AttrProxySource,\n\u001b[32m     89\u001b[39m     AttrSource,\n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m     TupleIteratorGetItemSource,\n\u001b[32m    108\u001b[39m )\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    110\u001b[39m     _extract_tensor_dict,\n\u001b[32m    111\u001b[39m     build_checkpoint_variable,\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m     wrap_fake_exception,\n\u001b[32m    141\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\_dynamo\\side_effects.py:21\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m graph_break_hints, utils, variables\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbytecode_transformation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     bytecode_from_template,\n\u001b[32m     17\u001b[39m     create_call_function,\n\u001b[32m     18\u001b[39m     create_call_method,\n\u001b[32m     19\u001b[39m     create_instruction,\n\u001b[32m     20\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcodegen\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PyCodegen\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SideEffectsError, unimplemented_v2\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01msource\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GlobalSource, LocalCellSource, LocalSource, Source\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\_dynamo\\codegen.py:43\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_safe_constant, rot_n_helper\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvariables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ValueMutationExisting, VariableTracker\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvariables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     44\u001b[39m     ContextlibContextManagerLocalGeneratorObjectVariable,\n\u001b[32m     45\u001b[39m     LocalGeneratorObjectVariable,\n\u001b[32m     46\u001b[39m )\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvariables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn_module\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NNModuleVariable\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvariables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     49\u001b[39m     NumpyNdarrayVariable,\n\u001b[32m     50\u001b[39m     SymNodeVariable,\n\u001b[32m     51\u001b[39m     TensorVariable,\n\u001b[32m     52\u001b[39m     UnspecializedPythonVariable,\n\u001b[32m     53\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\functions.py:71\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstant\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConstantVariable\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfsdp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_fully_shard\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _fsdp_param_group\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[32m     73\u001b[39m     _fsdp_param_group = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\distributed\\fsdp\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_flat_param\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FlatParameter \u001b[38;5;28;01mas\u001b[39;00m FlatParameter\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_fully_shard\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      3\u001b[39m     CPUOffloadPolicy,\n\u001b[32m      4\u001b[39m     FSDPModule,\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     UnshardHandle,\n\u001b[32m     10\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfully_sharded_data_parallel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     BackwardPrefetch,\n\u001b[32m     13\u001b[39m     CPUOffload,\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     StateDictType,\n\u001b[32m     28\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\distributed\\fsdp\\_flat_param.py:33\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparameter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _ParameterMeta  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtesting\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_internal\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_pg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeProcessGroup\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_fsdp_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     34\u001b[39m     _ext_post_unflatten_transform,\n\u001b[32m     35\u001b[39m     _ext_pre_flatten_transform,\n\u001b[32m     36\u001b[39m     FSDPExtensions,\n\u001b[32m     37\u001b[39m )\n\u001b[32m     40\u001b[39m __all__ = [\n\u001b[32m     41\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mFlatParameter\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     42\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mFlatParamHandle\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     46\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mHandleShardingStrategy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     47\u001b[39m ]\n\u001b[32m     49\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\distributed\\fsdp\\_fsdp_extensions.py:8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_shard\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msharded_tensor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ShardedTensor\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_shard\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msharded_tensor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mshard\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Shard\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfsdp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_shard_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     _all_gather_dtensor,\n\u001b[32m     10\u001b[39m     _create_chunk_dtensor,\n\u001b[32m     11\u001b[39m     _create_chunk_sharded_tensor,\n\u001b[32m     12\u001b[39m )\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeviceMesh, DTensor\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mFSDPExtensions\u001b[39;00m(ABC):\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\distributed\\fsdp\\_shard_utils.py:18\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_shard\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msharded_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     Shard,\n\u001b[32m     13\u001b[39m     ShardedTensor,\n\u001b[32m     14\u001b[39m     ShardedTensorMetadata,\n\u001b[32m     15\u001b[39m     TensorProperties,\n\u001b[32m     16\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_shard\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msharding_spec\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ShardMetadata\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeviceMesh, DTensor, Replicate, Shard \u001b[38;5;28;01mas\u001b[39;00m DShard\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_remote_device_str\u001b[39m(rank, device_type, num_devices_per_node):\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m device_type.lower() == \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\distributed\\tensor\\__init__.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_ops\u001b[39;00m  \u001b[38;5;66;03m# force import all built-in dtensor ops\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdevice_mesh\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeviceMesh, init_device_mesh  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      7\u001b[39m     distribute_module,\n\u001b[32m      8\u001b[39m     distribute_tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     zeros,\n\u001b[32m     16\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\distributed\\tensor\\_ops\\__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_conv_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_embedding_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_experimental_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\distributed\\tensor\\_ops\\_conv_ops.py:5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# implement matrix related ops for distributed tensor\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dtensor_spec\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DTensorSpec, TensorMeta\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_op_schema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpSchema, OutputSharding\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_ops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m register_prop_rule\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\distributed\\tensor\\_dtensor_spec.py:6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdevice_mesh\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeviceMesh\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplacement_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      7\u001b[39m     Partial,\n\u001b[32m      8\u001b[39m     Placement,\n\u001b[32m      9\u001b[39m     Replicate,\n\u001b[32m     10\u001b[39m     Shard,\n\u001b[32m     11\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTensorMeta\u001b[39;00m(NamedTuple):\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# simple named tuple to represent tensor metadata\u001b[39;00m\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# intentionally to stay simple only for sharding\u001b[39;00m\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# propagation purposes.\u001b[39;00m\n\u001b[32m     18\u001b[39m     shape: torch.Size\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\distributed\\tensor\\placement_types.py:10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_functional_collectives\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfuncol\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdevice_mesh\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeviceMesh\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_collective_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     fill_empty_tensor_to_shards,\n\u001b[32m     12\u001b[39m     mesh_broadcast,\n\u001b[32m     13\u001b[39m     mesh_scatter,\n\u001b[32m     14\u001b[39m     pad_tensor,\n\u001b[32m     15\u001b[39m     shard_dim_alltoall,\n\u001b[32m     16\u001b[39m     unpad_tensor,\n\u001b[32m     17\u001b[39m )\n\u001b[32m     20\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mPlacement\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mShard\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mReplicate\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mPartial\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPlacement\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\distributed\\tensor\\_collective_utils.py:29\u001b[39m\n\u001b[32m     24\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._running_with_deploy():\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;129;43m@torch\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlibrary\u001b[49m\u001b[43m.\u001b[49m\u001b[43mregister_fake\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_dtensor::shard_dim_alltoall\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43m_shard_dim_alltoall_meta\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgather_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshard_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroup_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_get_group_size_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstacked_list\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty_like\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\library.py:1023\u001b[39m, in \u001b[36mregister_fake.<locals>.register\u001b[39m\u001b[34m(func)\u001b[39m\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1022\u001b[39m     use_lib = lib\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m \u001b[43muse_lib\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_register_fake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacklevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstacklevel\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\library.py:193\u001b[39m, in \u001b[36mLibrary._register_fake\u001b[39m\u001b[34m(self, op_name, fn, _stacklevel)\u001b[39m\n\u001b[32m    190\u001b[39m     _library.utils.warn_deploy()\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m source = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_library\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_stacklevel\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m frame = sys._getframe(_stacklevel)\n\u001b[32m    195\u001b[39m caller_module = inspect.getmodule(frame)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ECE\\ECE1508\\PROJECT\\Personalized_Text-to-Speech\\.venv\\Lib\\site-packages\\torch\\_library\\utils.py:54\u001b[39m, in \u001b[36mget_source\u001b[39m\u001b[34m(stacklevel)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_source\u001b[39m(stacklevel: \u001b[38;5;28mint\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     46\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a string that represents the caller.\u001b[39;00m\n\u001b[32m     47\u001b[39m \n\u001b[32m     48\u001b[39m \u001b[33;03m    Example: \"/path/to/foo.py:42\"\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     52\u001b[39m \u001b[33;03m    etc.\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     frame = \u001b[43minspect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetframeinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_getframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstacklevel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     source = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframe.filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframe.lineno\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m source\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\inspect.py:1700\u001b[39m, in \u001b[36mgetframeinfo\u001b[39m\u001b[34m(frame, context)\u001b[39m\n\u001b[32m   1698\u001b[39m start = lineno - \u001b[32m1\u001b[39m - context//\u001b[32m2\u001b[39m\n\u001b[32m   1699\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1700\u001b[39m     lines, lnum = \u001b[43mfindsource\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1701\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m   1702\u001b[39m     lines = index = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\inspect.py:1075\u001b[39m, in \u001b[36mfindsource\u001b[39m\u001b[34m(object)\u001b[39m\n\u001b[32m   1072\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (file.startswith(\u001b[33m'\u001b[39m\u001b[33m<\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m file.endswith(\u001b[33m'\u001b[39m\u001b[33m>\u001b[39m\u001b[33m'\u001b[39m)):\n\u001b[32m   1073\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33msource code not available\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1075\u001b[39m module = \u001b[43mgetmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m module:\n\u001b[32m   1077\u001b[39m     lines = linecache.getlines(file, module.\u001b[34m__dict__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\inspect.py:998\u001b[39m, in \u001b[36mgetmodule\u001b[39m\u001b[34m(object, _filename)\u001b[39m\n\u001b[32m    996\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    997\u001b[39m _filesbymodname[modname] = f\n\u001b[32m--> \u001b[39m\u001b[32m998\u001b[39m f = \u001b[43mgetabsfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[38;5;66;03m# Always map to the name the module knows itself by\u001b[39;00m\n\u001b[32m   1000\u001b[39m modulesbyfile[f] = modulesbyfile[\n\u001b[32m   1001\u001b[39m     os.path.realpath(f)] = module.\u001b[34m__name__\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\inspect.py:967\u001b[39m, in \u001b[36mgetabsfile\u001b[39m\u001b[34m(object, _filename)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return an absolute path to the source or compiled file for an object.\u001b[39;00m\n\u001b[32m    963\u001b[39m \n\u001b[32m    964\u001b[39m \u001b[33;03mThe idea is for each object to have a unique origin, so this routine\u001b[39;00m\n\u001b[32m    965\u001b[39m \u001b[33;03mnormalizes the result as much as possible.\"\"\"\u001b[39;00m\n\u001b[32m    966\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m967\u001b[39m     _filename = \u001b[43mgetsourcefile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m getfile(\u001b[38;5;28mobject\u001b[39m)\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m os.path.normcase(os.path.abspath(_filename))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\inspect.py:949\u001b[39m, in \u001b[36mgetsourcefile\u001b[39m\u001b[34m(object)\u001b[39m\n\u001b[32m    946\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(filename.endswith(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m\n\u001b[32m    947\u001b[39m              importlib.machinery.EXTENSION_SUFFIXES):\n\u001b[32m    948\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    950\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m filename\n\u001b[32m    951\u001b[39m \u001b[38;5;66;03m# only return a non-existent filename if the module has a PEP 302 loader\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen genericpath>:19\u001b[39m, in \u001b[36mexists\u001b[39m\u001b[34m(path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "for text, text_len, mel, mel_len, gate, spk_id in loader:\n",
    "    text, text_len   = text.to(device), text_len.cuda()\n",
    "    mel, gate   = mel.cuda(), gate.cuda()\n",
    "    spk_emd = model.spk_emb[spk_id].to(device)  # Get speaker embedding from lookup table\n",
    "\n",
    "    mel_post, mel_out, gate_out, mu, logvar = model(text, text_len, mel, spk_emd)\n",
    "    loss, logs = cvae_taco_loss(mel_post, mel, gate_out, gate, mu, logvar)\n",
    "\n",
    "    optimizer.zero_grad(); loss.backward(); optimizer.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
